# âœ… Docker Airflow Setup - Complete

## ğŸ¯ What Was Updated

Your Docker setup now fully supports **Apache Airflow** alongside FastAPI and Streamlit.

## ğŸ“¦ Updated Files

### 1. **Dockerfile** - Enhanced with Airflow
- âœ… Added Airflow 2.8.1 installation
- âœ… Added Airflow providers (PostgreSQL, HTTP, Kafka, AWS)
- âœ… Created `/app/dags`, `/app/logs`, `/app/plugins` directories
- âœ… Set `AIRFLOW_HOME` environment variable
- âœ… Auto-initialize Airflow database on build

### 2. **docker-compose.yml** - Complete Orchestration
- âœ… Added PostgreSQL 15 service (Airflow metadata DB)
- âœ… Added Airflow Webserver (http://localhost:8080)
- âœ… Added Airflow Scheduler (background DAG orchestrator)
- âœ… Updated FastAPI and Streamlit to use network
- âœ… Added named volumes for persistence
- âœ… Added health checks and service dependencies
- âœ… Created `dashboard-network` for service communication

## ğŸ“„ New Documentation Files

### Core Setup Guides
1. **README.md** - Docker setup overview and basics
2. **AIRFLOW_SETUP.md** - Comprehensive Airflow guide (detailed)
3. **QUICK_REFERENCE.md** - Command cheat sheet

### Configuration
- **.env.example** - Template with all configuration options

### Scripts & Examples
- **start.sh** - Linux/Mac launcher script
- **start.ps1** - Windows PowerShell launcher
- **example_advanced_dags.py** - 4 production-ready DAG examples

## ğŸš€ Quick Start

### Windows (Your OS)
```powershell
cd docker
.\start.ps1
```

### Linux/Mac
```bash
cd docker
chmod +x start.sh
./start.sh
```

### Manual
```bash
cd docker
docker-compose up -d
```

## ğŸŒ Access Your Services

After starting, access:

| Service | URL | Purpose |
|---------|-----|---------|
| **Airflow UI** | http://localhost:8080 | DAG management (admin/admin) |
| **FastAPI** | http://localhost:8000/docs | API documentation |
| **Streamlit** | http://localhost:8501 | Dashboard UI |
| **PostgreSQL** | localhost:5432 | Database (airflow/airflow) |

## ğŸ“Š Service Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Compose Network                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚  â”‚  PostgreSQL 15   â”‚ â† Airflow Metadata Database  â”‚
â”‚  â”‚  Port: 5432      â”‚                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚         â†‘        â†‘                                  â”‚
â”‚         â”‚        â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Airflow Web  â”‚  â”‚ Airflow Scheduler    â”‚       â”‚
â”‚  â”‚ Port: 8080   â”‚  â”‚ (Background Service) â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â†‘                      â†‘                    â”‚
â”‚         â”‚                      â”‚                    â”‚
â”‚         â””â”€â”€â†’ DAGs (/dags) â†â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   FastAPI    â”‚  â”‚  Streamlit   â”‚               â”‚
â”‚  â”‚ Port: 8000   â”‚  â”‚ Port: 8501   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â†‘                  â†‘                        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚      (Service Communication)                      â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Key Features

### Airflow Features
âœ… Web UI for DAG monitoring  
âœ… Scheduler for automated execution  
âœ… PostgreSQL for metadata storage  
âœ… Health checks and auto-recovery  
âœ… Volume mounts for DAGs, logs, plugins  
âœ… Environment variable configuration  
âœ… Example DAGs ready to customize  

### Integration Features
âœ… FastAPI accessible from Airflow DAGs  
âœ… Shared data volume (`/app/data`)  
âœ… Streamlit dashboard for visualization  
âœ… All services on same network  
âœ… Persistent storage with named volumes  

## ğŸ“ File Organization

```
docker/
â”œâ”€â”€ Dockerfile                           (Multi-stage build)
â”œâ”€â”€ docker-compose.yml                   (5 services + network)
â”œâ”€â”€ .env.example                         (Configuration template)
â”œâ”€â”€ start.sh                             (Linux launcher)
â”œâ”€â”€ start.ps1                            (Windows launcher)
â”œâ”€â”€ README.md                            (Overview)
â”œâ”€â”€ AIRFLOW_SETUP.md                     (Detailed guide)
â”œâ”€â”€ QUICK_REFERENCE.md                   (Command cheatsheet)
â””â”€â”€ ...

dags/
â”œâ”€â”€ ai50_daily_refresh_dag.py           (Existing)
â”œâ”€â”€ ai50_full_ingest_dag.py             (Existing)
â””â”€â”€ example_advanced_dags.py            (NEW - Production examples)

data/
â”œâ”€â”€ ...existing data files...
â””â”€â”€ ...auto-generated logs...
```

## ğŸ”§ Configuration Options

Edit `.env` to customize:

```bash
# Executor type (LocalExecutor for single machine, CeleryExecutor for distributed)
AIRFLOW__CORE__EXECUTOR=LocalExecutor

# Database connection
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow

# PostgreSQL credentials
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow

# Scheduler behavior
AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT=false
```

## ğŸ“š Documentation Guide

### For Quick Setup (5 minutes)
â†’ Read `QUICK_REFERENCE.md`

### For Complete Understanding (30 minutes)
â†’ Read `README.md` then `AIRFLOW_SETUP.md`

### For DAG Development
â†’ Check `dags/example_advanced_dags.py` for 4 examples:
1. Basic FastAPI integration
2. Parallel processing
3. Data quality checks
4. Scheduled refresh

### For Troubleshooting
â†’ See `AIRFLOW_SETUP.md` Troubleshooting section

## âœ¨ What's Included

### 1. PostgreSQL Service
- Persistent metadata storage
- Health checks
- Auto-initialization
- Port 5432

### 2. Airflow Webserver
- Web UI on port 8080
- Username: admin
- Password: admin
- Auto-init database
- REST API available

### 3. Airflow Scheduler
- Background DAG orchestration
- Automatic DAG detection
- Task scheduling & execution
- Integrated logging

### 4. FastAPI Service
- Existing backend API
- Port 8000
- Accessible from Airflow DAGs

### 5. Streamlit Service
- Existing frontend dashboard
- Port 8501
- Ready for visualization

## ğŸš¦ Service Health Checks

All services have health checks configured:

```bash
# Check all
docker-compose ps

# Check specific
docker-compose logs postgres
docker-compose logs airflow-webserver
docker-compose logs airflow-scheduler
```

## ğŸ”„ Workflow Example

1. **Create DAG** in `dags/` folder
2. **Restart scheduler** (auto-detects):
   ```bash
   docker-compose restart airflow-scheduler
   ```
3. **View in Airflow UI** (http://localhost:8080)
4. **Trigger manually** or wait for schedule
5. **Monitor execution** in Airflow UI
6. **View results** in Streamlit or FastAPI

## ğŸ“ Common Commands

```bash
# Start everything
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f airflow-scheduler

# List DAGs
docker exec pe-dashboard-airflow-scheduler airflow dags list

# Stop everything
docker-compose down

# Clean everything (with data)
docker-compose down -v
```

## ğŸ” Security Notes

### Current Setup (Development)
- Airflow authentication disabled
- Simple credentials (admin/airflow)
- Suitable for local development only

### For Production
- Enable `AIRFLOW__WEBSERVER__AUTHENTICATE=true`
- Use strong passwords
- Set up SSL/TLS
- Use external managed PostgreSQL
- Configure proper RBAC
- Set up monitoring & alerting

## ğŸ¯ Next Steps

1. **Start the services**
   ```bash
   cd docker
   .\start.ps1  # Windows
   ```

2. **Wait for initialization** (30 seconds)

3. **Open Airflow UI**
   - URL: http://localhost:8080
   - Login: admin / admin

4. **View your DAGs**
   - Should see `ai50_daily_refresh_dag` and `ai50_full_ingest_dag`

5. **Trigger a DAG**
   - Click on DAG name
   - Click "Trigger" button
   - Monitor in "Graph" view

6. **Create new DAGs**
   - Add to `dags/` folder
   - Scheduler auto-detects within 1 minute

## ğŸ“Š Performance Considerations

### Default Configuration
- LocalExecutor (single machine)
- 1 scheduler process
- PostgreSQL in Docker (not production-ready)
- Suitable for: Development, testing, small workloads

### Scale to Production
- Switch to CeleryExecutor
- Add Redis/RabbitMQ broker
- Use external PostgreSQL (RDS, CloudSQL)
- Add multiple scheduler/worker instances
- Configure resource limits
- Set up monitoring

## âœ… Verification Checklist

After running `docker-compose up -d`:

- [ ] All 5 containers running (`docker-compose ps`)
- [ ] Airflow UI loads (http://localhost:8080)
- [ ] FastAPI docs accessible (http://localhost:8000/docs)
- [ ] Streamlit dashboard loads (http://localhost:8501)
- [ ] DAGs visible in Airflow UI
- [ ] PostgreSQL logs show no errors
- [ ] Scheduler logs show DAGs detected

## ğŸ‰ You're All Set!

Your Airflow environment is fully configured and ready to use!

### Quick Commands to Try

```bash
# View all DAGs
docker exec pe-dashboard-airflow-scheduler airflow dags list

# See next execution time
docker exec pe-dashboard-airflow-scheduler airflow dags next-execution ai50_daily_refresh_dag

# Manually trigger
docker exec pe-dashboard-airflow-webserver airflow dags trigger ai50_daily_refresh_dag
```

---

## ğŸ“– Documentation Summary

| File | Purpose | Read Time |
|------|---------|-----------|
| **README.md** | Docker overview & setup | 10 min |
| **AIRFLOW_SETUP.md** | Detailed Airflow guide | 20 min |
| **QUICK_REFERENCE.md** | Command cheatsheet | 5 min |
| **example_advanced_dags.py** | Production DAG examples | 15 min |

---

**Setup Complete!** ğŸš€

Your Docker environment now supports Apache Airflow with FastAPI and Streamlit fully integrated and ready for production workflows!
