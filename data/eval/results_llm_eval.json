{
  "abridge": {
    "structured": {
      "company_name": "Abridge",
      "company_slug": "abridge",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:45:00.770701",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies compared to the ground truth. The funding details, such as the total raised amount and valuation, do not match the known facts. Additionally, the response includes specific product names and partnerships not mentioned in the ground truth, which could not be verified. However, there are no known hallucinations present in the response. The structure of the response is compliant with the expected format, and it is well-organized and easy to read. The most important facts, such as the company's focus and mission, are not prioritized at the beginning of the response, affecting the MRR score. There is a lack of citations or sources for the claims made, resulting in a low provenance quality score.",
      "total_score": 6.5
    },
    "rag": {
      "company_name": "Abridge",
      "company_slug": "abridge",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:45:04.696618",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 1,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies compared to the ground truth. The funding details and valuation are inconsistent with the context results, which show different figures. The response claims a total funding of $773 million and a valuation of $5.3 billion, but the context suggests a total funding of $320 million as of September 2025. The response also lacks proper citations for its claims, leading to a provenance quality score of 0. There are no known hallucinations, but the presence of unverifiable claims results in a hallucination detection score of 1. The response is well-structured and readable, earning full marks for schema compliance and readability. The most important facts are not prioritized, resulting in an MRR score of 0.5. Overall, the response has notable factual errors and lacks proper sourcing, impacting its total score.",
      "total_score": 5.5
    }
  },
  "world-labs": {
    "structured": {
      "company_name": "World Labs",
      "company_slug": "world-labs",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:44:53.046223",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies. The founding details and key investors are missing, and the funding amount is slightly off as it doesn't specify the leading investors. The mention of Marble as a product is not in the ground truth. However, the response does correctly mention RTFM and the focus on 3D world models. Schema compliance is perfect as the response is well-structured. Provenance quality is poor as there are no citations or sources provided for the claims. There are no hallucinations detected as all claims are verifiable against the ground truth. The readability is clear and well-organized. The MRR score is 0.5 as the response does not prioritize the most important facts first, such as the founding details and key investors.",
      "total_score": 6.5
    },
    "rag": {
      "company_name": "World Labs",
      "company_slug": "world-labs",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:44:56.871200",
      "factual_accuracy": 2,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 1.0,
      "notes": "The response accurately describes World Labs as a spatial intelligence company building LWMs and mentions the co-founders correctly. However, there are discrepancies in the funding details: the response states $230M was raised in a Series D round in 2024, while the ground truth mentions $230M in total funding without specifying the round. The response lacks proper citations for its claims, affecting provenance quality. The response is well-structured and readable, with important facts appearing first. No hallucinations were detected.",
      "total_score": 8.0
    }
  },
  "anthropic": {
    "structured": {
      "company_name": "Anthropic",
      "company_slug": "anthropic",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:45:08.342932",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 1,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies and lacks proper citations. The claim about Anthropic being branded as Claude and the rapid revenue growth are not supported by the ground truth. The structure of the response is compliant with the expected format, but the provenance quality is poor as there are no citations for the claims made. There are no known hallucinations, but unverifiable claims exist. The response is clear and well-organized, and the most important fact about the funding round is mentioned, but other key facts are missing or not prioritized.",
      "total_score": 5.5
    },
    "rag": {
      "company_name": "Anthropic",
      "company_slug": "anthropic",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:45:21.641574",
      "factual_accuracy": 2,
      "schema_compliance": 2,
      "provenance_quality": 1,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 1.0,
      "notes": "The response accurately captures most of the ground truth facts, such as Anthropic's focus on AI safety, its status as a public benefit corporation, and the details of its Series F funding round. However, there are minor discrepancies, such as the omission of specific ground truth facts like the Anthropic Economic Index report. The response follows the expected structure and format perfectly. Provenance quality is rated 1 because while some claims are supported by context results, not all claims have direct citations. There are no hallucinations detected, and the response is clear and well-organized. Important facts, such as the company's focus on AI safety and its recent funding round, are presented prominently, justifying a high MRR score.",
      "total_score": 9.0
    }
  },
  "anysphere": {
    "structured": {
      "company_name": "Anysphere",
      "company_slug": "anysphere",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:45:24.221457",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies compared to the ground truth. It mentions a Series D funding round and a $1 billion revenue milestone, which are not present in the ground truth. The response does not provide citations or sources for its claims, leading to a low provenance quality score. However, the response is well-structured and readable, with no known hallucinations. Important facts about the company's products and their benefits are not prioritized in the response, affecting the MRR score.",
      "total_score": 6.5
    },
    "rag": {
      "company_name": "Anysphere",
      "company_slug": "anysphere",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:45:42.936939",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 1,
      "hallucination_detection": 1,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies compared to the ground truth. While it correctly mentions the use of Cursor by companies like Salesforce, NVIDIA, and PwC, it inaccurately claims Anysphere has raised $2.3 billion in Series D funding and has a valuation of $29.3 billion, which is not verified by the context results. Additionally, the claim of Anysphere's annualized revenue surpassing $1 billion is not supported by the provided context. The response follows the expected structure well and is readable. However, the provenance quality is low as many claims lack proper citations. There are minor unverifiable claims, but no major hallucinations. Important facts about the company's product and its use by enterprises are mentioned early in the response, but some critical financial details are inaccurate or unverifiable.",
      "total_score": 6.5
    }
  },
  "baseten": {
    "structured": {
      "company_name": "Baseten",
      "company_slug": "baseten",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:45:47.374584",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies compared to the ground truth. It mentions products and services like 'Baseten Cloud', 'Dedicated Deployments', and 'Inference Stack', which are not part of the provided ground truth. The ground truth focuses on 'Chains' for orchestrating inference workflows and building products for engineering and ML teams, which are not mentioned in the response. However, there are no known hallucinations present in the response.\n\nThe schema compliance is perfect as the response follows a clear and expected structure. However, provenance quality is poor as there are no citations or sources provided for the claims made. The readability of the response is good, being clear and well-organized. The mean reciprocal ranking is average as the response does not prioritize the most important facts from the ground truth, such as the focus on 'Chains' and building products for engineering teams.",
      "total_score": 6.5
    },
    "rag": {
      "company_name": "Baseten",
      "company_slug": "baseten",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:46:04.772425",
      "factual_accuracy": 2,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response accurately describes Baseten's focus on AI infrastructure and tooling, aligning with the ground truth. However, it introduces additional details such as the CEO's name, location, and specific funding details, which are not present in the ground truth but are not known hallucinations. The response follows the expected structure well, but lacks proper citations for its claims, resulting in a low provenance quality score. The content is clear and well-organized, and the most important facts about the company's focus on AI infrastructure appear early in the response.",
      "total_score": 7.5
    }
  },
  "captions": {
    "structured": {
      "company_name": "Captions",
      "company_slug": "captions",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:46:08.690746",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies compared to the ground truth. Notably, the rebranding from Captions to Mirage is not mentioned in the ground truth, and the founding year of 2023 is not provided in the ground truth. The funding amount and investment in AI video research align with the ground truth, but the total raised amount and valuation are not mentioned in the ground truth. The response follows the expected structure well, earning full schema compliance points. However, there are no citations or sources provided for the claims, resulting in a provenance quality score of 0. There are no hallucinations detected, as all claims are verifiable against the ground truth or are not known hallucinations. The readability is clear and well-organized. The most important facts, such as the company's focus and funding, are mentioned early in the response, but some key facts from the ground truth are missing or not prioritized, resulting in an MRR score of 0.5.",
      "total_score": 6.5
    },
    "rag": {
      "company_name": "Captions",
      "company_slug": "captions",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:46:27.199994",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 1,
      "hallucination_detection": 1,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies. The founding year is correct, but the headquarters is incorrectly stated as New York City instead of Boston. The Series C funding amount and investors are correct, but the total funding amount and number of rounds are inconsistent with the ground truth. The statement about the company's vision aligns with the ground truth. The response is well-structured and readable. Provenance quality is moderate as not all claims are directly supported by the context results. There are no known hallucinations, but some unverifiable claims exist. Important facts such as the company's vision and funding are mentioned early, but the location error affects the factual accuracy score.",
      "total_score": 6.5
    }
  },
  "clay": {
    "structured": {
      "company_name": "Clay",
      "company_slug": "clay",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:46:30.808263",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 1,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies compared to the ground truth. The founding year is stated as 2025, which is unlikely given the Series B and Series C funding rounds mentioned. The Series C announcement is not mentioned, and the GTM engineering era is not highlighted as per the ground truth. The response does not provide citations or sources for the claims made, leading to a provenance quality score of 0. There are no known hallucinations, but some unverifiable claims exist, resulting in a hallucination detection score of 1. The response is well-structured and readable, earning full marks for schema compliance and readability. However, the most important facts, such as the Series C announcement and GTM engineering focus, are not prioritized, resulting in a MRR score of 0.5.",
      "total_score": 5.5
    },
    "rag": {
      "company_name": "Clay",
      "company_slug": "clay",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:47:07.642898",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 1,
      "hallucination_detection": 1,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies compared to the ground truth. For instance, the response mentions Clay's Series C valuation at $3.1 billion in 2025, which is not confirmed in the ground truth. The response also includes details about products and investors that are not mentioned in the ground truth. However, it does correctly identify Clay's focus on GTM workflows and AI-driven tools. The schema compliance is perfect as the response is well-structured and follows the expected format. Provenance quality is moderate as some claims lack proper citations. There are minor unverifiable claims, but no major hallucinations, hence a score of 1 for hallucination detection. The readability is clear and well-organized, deserving a score of 1. The most important facts appear second, so the MRR score is 0.5. The total score is 6.5.",
      "total_score": 6.5
    }
  },
  "coactive-ai": {
    "structured": {
      "company_name": "Coactive AI",
      "company_slug": "coactive-ai",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:47:12.727052",
      "factual_accuracy": 2,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response provides a generally accurate overview of Coactive AI, matching several key facts from the ground truth, such as the focus on AI platforms and the Series B funding round. However, there are discrepancies, such as the founding year (2021 vs. not mentioned in ground truth) and the partnership with NBCUniversal, which is not mentioned in the ground truth. The response is well-structured and follows the expected format, earning full marks for schema compliance. However, there are no citations or sources provided for the claims, resulting in a score of 0 for provenance quality. No hallucinations were detected, and the response is clear and well-organized. The most important facts, such as the Series B funding and platform capabilities, are mentioned early in the response, but some key details like the company's diversity and expertise are missing or not prioritized, resulting in a moderate MRR score.",
      "total_score": 7.5
    },
    "rag": {
      "company_name": "Coactive AI",
      "company_slug": "coactive-ai",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:47:26.178348",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 1,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response contains several factual inaccuracies: the founding year, founders, and employee count do not match the ground truth. The response does not mention the Coactive Multimodal AI Platform's specific features like handling massive scale or Azure integration. However, it correctly identifies the Series B funding round and some investors. The structure is compliant with the expected format. Provenance is partially provided, but not all claims are sourced. No hallucinations were detected. The response is clear and well-organized. Important facts like the Series B funding are mentioned early, but some key details are missing or not prioritized.",
      "total_score": 7.5
    }
  },
  "cohere": {
    "structured": {
      "company_name": "Cohere",
      "company_slug": "cohere",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:47:29.964925",
      "factual_accuracy": 2,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response provides a comprehensive overview of Cohere, aligning well with the ground truth in terms of the company's focus on enterprise AI solutions and recent funding activities. However, there are some factual discrepancies: the founding year and headquarters location are not mentioned in the ground truth, and the product names (North, Compass, Command, Rerank) are not verified against the ground truth. The response is well-structured and readable, following the expected schema perfectly. However, it lacks citations for the claims made, resulting in a low provenance quality score. No hallucinations were detected, and the most important facts about funding and enterprise focus appear early in the response, though not at the very beginning. Overall, the response is mostly accurate but could benefit from better sourcing and verification of specific details.",
      "total_score": 7.5
    },
    "rag": {
      "company_name": "Cohere",
      "company_slug": "cohere",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:47:54.176847",
      "factual_accuracy": 2,
      "schema_compliance": 2,
      "provenance_quality": 1,
      "hallucination_detection": 2,
      "readability": 1,
      "mrr_score": 1.0,
      "notes": "The response is mostly accurate but contains some discrepancies. The factual accuracy is rated 2 because while most facts align with the ground truth, there are minor discrepancies such as the absence of specific funding details and the number of funding rounds. Schema compliance is rated 2 as the response follows the expected structure well. Provenance quality is rated 1 because while there are some sources, not all claims are directly supported by the context results. Hallucination detection is rated 2 as there are no known hallucinations present. Readability is rated 1 as the response is clear and well-organized. MRR score is 1.0 as the most important facts appear first. Total score is 9.0.",
      "total_score": 9.0
    }
  },
  "crusoe": {
    "structured": {
      "company_name": "Crusoe",
      "company_slug": "crusoe",
      "pipeline_type": "structured",
      "timestamp": "2025-11-21T19:47:59.293059",
      "factual_accuracy": 1,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 1,
      "readability": 1,
      "mrr_score": 0.5,
      "notes": "The response provides some accurate information about Crusoe, such as its focus on high-performance computing and energy sectors, but it lacks alignment with the ground truth facts provided. The response does not mention the specific benefits of Crusoe's AI-optimized infrastructure, such as the 20x faster deployment or 81% cost reduction. It also fails to highlight the specific products and innovations mentioned in the ground truth, like the PyTorch image classification guide or the NVIDIA GB200 NVL72. There are no hallucinations from the known examples, but the response includes unverifiable claims about funding and partnerships without proper citations. The structure of the response is well-organized, and the most important facts about the company's business model and growth are mentioned early, but the lack of alignment with the ground truth affects the factual accuracy score.",
      "total_score": 5.5
    },
    "rag": {
      "company_name": "Crusoe",
      "company_slug": "crusoe",
      "pipeline_type": "rag",
      "timestamp": "2025-11-21T19:48:15.218787",
      "factual_accuracy": 2,
      "schema_compliance": 2,
      "provenance_quality": 0,
      "hallucination_detection": 1,
      "readability": 1,
      "mrr_score": 1.0,
      "notes": "The response contains mostly accurate information but has some discrepancies compared to the ground truth. For example, the response mentions Crusoe's founding year as 2018 and its focus on sustainability and renewable energy, which aligns with the ground truth. However, it does not mention specific ground truth facts such as the 20x faster deployment or the specific NVIDIA GB200 NVL72 technology. The response is well-structured and follows the expected format, earning full schema compliance points. However, it lacks proper citations for the claims made, resulting in a provenance quality score of 0. There are no known hallucinations, but some claims are unverifiable, leading to a hallucination detection score of 1. The response is clear and well-organized, earning full readability points. Important facts are presented early in the response, resulting in a full MRR score. The total score is 7.",
      "total_score": 7.0
    }
  }
}